{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39m# Formatting\u001b[39;00m\n\u001b[0;32m     31\u001b[0m current_timezone \u001b[39m=\u001b[39m pytz\u001b[39m.\u001b[39mtimezone(\u001b[39m'\u001b[39m\u001b[39mUTC\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mTime (US/Pacific)\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mTime (+0)\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mdt\u001b[39m.\u001b[39mtz_localize(current_timezone)\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mtz_convert(\u001b[39m'\u001b[39m\u001b[39mUS/Pacific\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     33\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mTime (+0)\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     34\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mTime (PDT)\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mTime\u001b[39m\u001b[39m'\u001b[39m})\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:5989\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5982\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   5983\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[0;32m   5984\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[0;32m   5985\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[0;32m   5986\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5987\u001b[0m ):\n\u001b[0;32m   5988\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[1;32m-> 5989\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[39m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor(obj)\n\u001b[0;32m    225\u001b[0m \u001b[39m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[39m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[39m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[39m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\accessors.py:580\u001b[0m, in \u001b[0;36mCombinedDatetimelikeProperties.__new__\u001b[1;34m(cls, data)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[39melif\u001b[39;00m is_period_dtype(data\u001b[39m.\u001b[39mdtype):\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m PeriodProperties(data, orig)\n\u001b[1;32m--> 580\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCan only use .dt accessor with datetimelike values\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytz\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('2musk_tweets.csv', encoding='utf-8')\n",
    "\n",
    "# Append the row entries to an array\n",
    "data_array = df.values.tolist()\n",
    "\n",
    "# Define the processing function\n",
    "def process_tweet(tweet):\n",
    "    if isinstance(tweet, float):\n",
    "        return \"\"\n",
    "    tweet_words = []\n",
    "    for word in tweet.split(' '):\n",
    "        if word.startswith('@') and len(word) > 1:\n",
    "            word = '@user'\n",
    "        elif word.startswith('http'):\n",
    "            word = \"http\"\n",
    "        tweet_words.append(word)\n",
    "    tweet_processed = \" \".join(tweet_words)\n",
    "    return tweet_processed\n",
    "\n",
    "# Apply the processing function to the 'Tweet' column and store the results in a new column\n",
    "df['Tweet'] = df['Tweet'].apply(process_tweet)\n",
    "\n",
    "# Formatting\n",
    "current_timezone = pytz.timezone('UTC')\n",
    "df['Time (US/Pacific)'] = df['Time (+0)'].dt.tz_localize(current_timezone).dt.tz_convert('US/Pacific')\n",
    "df = df.drop(columns=['Time (+0)'])\n",
    "df = df.rename(columns={'Time (US/Pacific)': 'Time'})\n",
    "\n",
    "print(df)\n",
    "df.to_csv('3processed_tweets.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Time (+0)                                              Tweet   \n",
      "0    2023-05-11 10:11:16                    @user @user @user Probably true  \\\n",
      "1    2023-05-11 10:08:59          @user Major update coming in a few months   \n",
      "2    2023-05-11 09:32:11  RT @user Starship is the largest, most capable...   \n",
      "3    2023-05-11 09:24:48  @user Then he added ‚ÄúSilicon is for n00bs, Gal...   \n",
      "4    2023-05-11 09:17:47                   @user @user @user @user @user üòÇüíØ   \n",
      "..                   ...                                                ...   \n",
      "345  2023-05-04 18:04:34                       @user Thanks for the 3 Doge!   \n",
      "346  2023-05-04 18:01:57  @user True, electronics all want DC, not AC. S...   \n",
      "347  2023-05-04 17:58:59                   @user Welcome back to Twitter! üíï   \n",
      "348  2023-05-04 17:56:08                    May the 4th be with you ‚ù§Ô∏è http   \n",
      "349  2023-05-04 17:48:32  @user @user Yes, but they are not to blame for...   \n",
      "\n",
      "    Sentiment Negative Score Neutral Score Positive Score  \n",
      "0     Neutral        0.01171      0.920015       0.068275  \n",
      "1     Neutral       0.004564      0.715443       0.279993  \n",
      "2    Positive       0.001439      0.005551        0.99301  \n",
      "3     Neutral       0.006513      0.964699       0.028788  \n",
      "4     Neutral       0.010035      0.541732       0.448233  \n",
      "..        ...            ...           ...            ...  \n",
      "345  Positive       0.001509      0.006189       0.992302  \n",
      "346   Neutral       0.022207      0.683745       0.294048  \n",
      "347  Positive       0.001325      0.009529       0.989146  \n",
      "348  Positive       0.001573      0.006058        0.99237  \n",
      "349  Negative       0.844547      0.140118       0.015335  \n",
      "\n",
      "[350 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# load model and tokenizer\n",
    "roberta = \"cardiffnlp/roberta-base-tweet-sentiment-en\" # https://huggingface.co/cardiffnlp/roberta-base-tweet-sentiment-en/tree/main\n",
    "model = AutoModelForSequenceClassification.from_pretrained(roberta)\n",
    "tokenizer = AutoTokenizer.from_pretrained(roberta)\n",
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "df['Sentiment'] = ''\n",
    "df['Negative Score'] = ''\n",
    "df['Neutral Score'] = ''\n",
    "df['Positive Score'] = ''\n",
    "\n",
    "# Perform sentiment analysis\n",
    "for index, row in df.iterrows():\n",
    "    tweet = row['Tweet']\n",
    "    encoded_tweet = tokenizer(tweet, return_tensors='pt')\n",
    "    output = model(**encoded_tweet)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "\n",
    "    df.at[index, 'Sentiment'] = labels[scores.argmax()]\n",
    "    df.at[index, 'Negative Score'] = scores[0]\n",
    "    df.at[index, 'Neutral Score'] = scores[1]\n",
    "    df.at[index, 'Positive Score'] = scores[2]\n",
    "\n",
    "# # Print sentiment labels and scores\n",
    "# for i in range(len(scores)):\n",
    "#     label = labels[i]\n",
    "#     score = scores[i]\n",
    "#     print(\"Tweet:\", tweet)\n",
    "#     print(\"Sentiment:\", label)\n",
    "#     print(\"Score:\", score)\n",
    "#     print()\n",
    "\n",
    "print(df)\n",
    "df.to_csv('4sentiment.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
